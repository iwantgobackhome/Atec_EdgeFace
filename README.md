# EdgeFace - Face Alignment Benchmark & Real-time Recognition System

EdgeFace ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì–¼êµ´ ì •ë ¬(Face Alignment) ë°©ë²•ë“¤ì˜ ì„±ëŠ¥ ë¹„êµ ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œ ë° ì‹¤ì‹œê°„ ì–¼êµ´ ì¸ì‹ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ğŸ“‹ í”„ë¡œì íŠ¸ êµ¬ì¡°

### ğŸš€ ë©”ì¸ ì‹¤í–‰ íŒŒì¼

#### NPU Calibration ì‹œìŠ¤í…œ (NEW! ğŸ”¥)
- **`npu_calibration/`** - YuNet/EdgeFace ONNX â†’ NPU ì»´íŒŒì¼ìš© calibration ì‹œìŠ¤í…œ
  - **ìë™í™”ëœ ê³ í’ˆì§ˆ calibration ë°ì´í„°ì…‹ ìƒì„±**
  - **YuNetìš©**: ì¼ë°˜ ì´ë¯¸ì§€ ì„ íƒ ë° í’ˆì§ˆ ë¶„ì„
  - **EdgeFaceìš©**: YuNetìœ¼ë¡œ ì–¼êµ´ ì •ë ¬ í›„ calibration ë°ì´í„° ìƒì„±
  - **NPU calibration config JSON ìë™ ìƒì„±**
  - 4ê°€ì§€ calibration ë°©ë²• ì§€ì› (EMA, MinMax, KL, Percentile)
  - ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ê²€ì¦ ë„êµ¬ í¬í•¨
  - [ìƒì„¸ ê°€ì´ë“œ ë³´ê¸°](npu_calibration/README.md)

#### ONNX ë³€í™˜ ë° í‰ê°€ (NEW! ğŸ”¥)
- **`edgeface_to_onnx_with_lfw_evaluation.ipynb`** - EdgeFace PyTorch â†’ ONNX ë³€í™˜ ë° LFW í‰ê°€
  - PyTorch ëª¨ë¸ì„ ONNX í˜•ì‹ìœ¼ë¡œ ë³€í™˜
  - NPU calibration configì™€ ì¼ì¹˜í•˜ëŠ” ì…ë ¥ ì´ë¦„ ì‚¬ìš© (input.1)
  - ONNX ëª¨ë¸ ê²€ì¦ ë° ì¶œë ¥ ë¹„êµ
  - LFW ë°ì´í„°ì…‹ìœ¼ë¡œ PyTorch vs ONNX ì„±ëŠ¥ ë¹„êµ
  - ROC ì»¤ë¸Œ, ì •í™•ë„, EER, ì²˜ë¦¬ ì†ë„ ë¹„êµ ë¶„ì„
  - ìœ ì‚¬ë„ ë¶„í¬ ì‹œê°í™”
  - í•œêµ­ì–´ ì„¤ëª… í¬í•¨

#### ì‹¤ì‹œê°„ ì–¼êµ´ ì¸ì‹ ì‹œìŠ¤í…œ (NEW! NPU ì§€ì› ğŸš€)
- **`face_recognition_gui.py`** - GUI ê¸°ë°˜ ì‹¤ì‹œê°„ ì–¼êµ´ ì¸ì‹ ì‹œìŠ¤í…œ (ê¶Œì¥)
  - Tkinter ê¸°ë°˜ ì§ê´€ì ì¸ GUI ì¸í„°í˜ì´ìŠ¤
  - ì‹¤ì‹œê°„ ì¹´ë©”ë¼ í”¼ë“œ ë° ì–¼êµ´ detection/recognition
  - ì°¸ì¡° ì´ë¯¸ì§€ ì¶”ê°€/ì‚­ì œ ê´€ë¦¬
  - Detection ëª¨ë¸ ì„ íƒ (MTCNN, YuNet, **YuNet NPU**, YOLO ë“±)
  - **DeepX NPU ê°€ì† ì§€ì›** - CPU/GPU/NPU ì„ íƒ ê°€ëŠ¥
  - FPS, ì¸ë¬¼ ID, ìœ ì‚¬ë„ ì‹¤ì‹œê°„ í‘œì‹œ
  - ğŸ“– [NPU ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ](QUICKSTART_NPU.md) | [ìƒì„¸ NPU í†µí•© ë¬¸ì„œ](NPU_INTEGRATION.md)

#### NPU í†µí•© ëª¨ë“ˆ (NEW! ğŸš€)
- **`face_alignment/yunet_npu.py`** - YuNet NPU ì–¼êµ´ ê²€ì¶œê¸°
  - DeepX NPU SDK ê¸°ë°˜ YuNet detector
  - 640x640 ì…ë ¥, 5-point ëœë“œë§ˆí¬ ê²€ì¶œ
  - âœ… Multi-scale FPN ì¶œë ¥ ë””ì½”ë”© ì™„ë£Œ
  - âœ… Anchor-based bbox/landmark decoding êµ¬í˜„

- **`edgeface_npu_recognizer.py`** - EdgeFace NPU ì¸ì‹ê¸°
  - DeepX NPU SDK ê¸°ë°˜ EdgeFace recognizer
  - 112x112 ì…ë ¥, 512ì°¨ì› ì„ë² ë”© ì¶œë ¥
  - âœ… L2 ì •ê·œí™”ëœ ì„ë² ë”© ì¶œë ¥ í™•ì¸ ì™„ë£Œ

- **`test_npu_inference.py`** - NPU ëª¨ë¸ í†µí•© í…ŒìŠ¤íŠ¸
  - YuNetê³¼ EdgeFace NPU ëª¨ë¸ ë™ì‹œ í…ŒìŠ¤íŠ¸
  - ì¶œë ¥ shape, í†µê³„, L2 norm ë¶„ì„
  - ì„ë² ë””ë“œ ë³´ë“œì—ì„œ ì‹¤í–‰ ê¶Œì¥

- **`face_recognition_system.py`** - ì»¤ë§¨ë“œë¼ì¸ ê¸°ë°˜ ì–¼êµ´ ì¸ì‹ ì‹œìŠ¤í…œ
  - EdgeFace ê¸°ë°˜ ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ
  - ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ì–¼êµ´ ê²€ì¦
  - ì°¸ì¡° ì´ë¯¸ì§€ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬
  - ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ì²˜ë¦¬

#### LFW ë²¤ì¹˜ë§ˆí¬
- **`face_alignment_benchmark_gpu.py`** - GPU ìµœì í™”ëœ LFW ë²¤ì¹˜ë§ˆí¬ ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸
  - ì—¬ëŸ¬ face alignment ë°©ë²•ì„ LFW ë°ì´í„°ì…‹ì—ì„œ ë¹„êµ í‰ê°€
  - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì  (CPU/GPU)
  - 6ê°€ì§€ ë©”íŠ¸ë¦­ ì‹œê°í™” (ì •í™•ë„, ì†ë„, ì„±ê³µë¥ , EER, ë©”ëª¨ë¦¬)

- **`lfw_evaluation_optimized.py`** - ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™” LFW í‰ê°€ ëª¨ë“ˆ
  - GPU íš¨ìœ¨ì„±ì„ ìœ„í•œ ë°°ì¹˜ ì„ë² ë”© ì¶”ì¶œ
  - ë³‘ë ¬ ì´ë¯¸ì§€ ë¡œë”© (ThreadPoolExecutor)
  - EdgeFace ëª¨ë¸ ê¸°ë°˜ ì–¼êµ´ ê²€ì¦

- **`lfw_evaluation.py`** - ê¸°ë³¸ LFW í‰ê°€ ëª¨ë“ˆ (ë°±ì—…ìš©)

### ğŸ” Face Alignment ëª¨ë“ˆ (`face_alignment/`)

#### í†µí•© ì¸í„°í˜ì´ìŠ¤
- **`unified_detector.py`** - ëª¨ë“  face detection ë°©ë²•ì˜ í†µí•© ì¸í„°í˜ì´ìŠ¤
  - ë‹¨ì¼ APIë¡œ ì—¬ëŸ¬ detector ì‚¬ìš© ê°€ëŠ¥
  - ìë™ ì˜ì¡´ì„± ì²´í¬
  - ë²¤ì¹˜ë§ˆí¬ ê¸°ëŠ¥ ë‚´ì¥

#### Face Detectors
- **`mtcnn.py`** - MTCNN (Multi-task CNN) detector
  - PyTorch ê¸°ë°˜
  - GPU/CPU ì§€ì›
  - 5ê°œ ëœë“œë§ˆí¬ ê²€ì¶œ

- **`yunet.py`** - YuNet detector
  - OpenCV DNN ê¸°ë°˜
  - CUDA ìë™ fallback ì§€ì›
  - ë¹ ë¥¸ ì†ë„

- **`yunet_npu.py`** - YuNet NPU detector (NEW! ğŸš€)
  - DeepX NPU SDK ê¸°ë°˜
  - ì„ë² ë””ë“œ ë³´ë“œ ìµœì í™”
  - 640x640 ì…ë ¥, 5-point ëœë“œë§ˆí¬
  - âœ… ì¶œë ¥ ë””ì½”ë”© ì™„ë£Œ (anchor-based detection)

- **`yolo_detector.py`** - YOLO ê¸°ë°˜ detectors
  - YOLOv5-Face: ì–¼êµ´ íŠ¹í™” ONNX ëª¨ë¸
  - YOLOv8: Ultralytics ë²”ìš© ëª¨ë¸
  - ë†’ì€ ì •í™•ë„

- **`retinaface_onnx.py`** - RetinaFace detector
  - ONNX Runtime ê¸°ë°˜
  - ë†’ì€ ê²€ì¶œ ì •í™•ë„

- **`rtmpose_detector.py`** - RTMPose detector
  - ì–¼êµ´ í‚¤í¬ì¸íŠ¸ ê²€ì¶œ
  - ONNX Runtime ê¸°ë°˜

- **`mediapipe_detector.py`** - MediaPipe detectors
  - MediaPipe Face Mesh: 468 ëœë“œë§ˆí¬
  - MediaPipe Face Detection: 6 ëœë“œë§ˆí¬
  - ë¹ ë¥´ê³  ê°€ë²¼ì›€

#### MTCNN ì˜ì¡´ì„±
- **`mtcnn_pytorch/`** - MTCNN PyTorch êµ¬í˜„ì²´
  - `src/detector.py` - MTCNN í•µì‹¬ detector
  - `src/align_trans.py` - ì–¼êµ´ ì •ë ¬ ë³€í™˜
  - `src/get_nets.py` - P-Net, R-Net, O-Net ëª¨ë¸
  - `src/box_utils.py` - Bounding box NMS

### ğŸ¯ ì›ë³¸ EdgeFace ì½”ë“œ

#### ëª¨ë¸ ê´€ë ¨
- **`backbones/`** - EdgeFace ëª¨ë¸ ë°±ë³¸ ì•„í‚¤í…ì²˜
  - `timmfr.py` - Timm ê¸°ë°˜ feature extractor

#### í•™ìŠµ ê´€ë ¨
- **`train_v2.py`** - EdgeFace ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
- **`train_v2_restart.py`** - ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘
- **`dataset.py`** - ì–¼êµ´ ì¸ì‹ ë°ì´í„°ì…‹ ë¡œë”
- **`losses.py`** - ì†ì‹¤ í•¨ìˆ˜ (ArcFace, CosFace ë“±)
- **`lr_scheduler.py`** - í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
- **`partial_fc_v2.py`** - Partial FC êµ¬í˜„

#### í‰ê°€ ê´€ë ¨
- **`eval/`** - ëª¨ë¸ í‰ê°€ ëª¨ë“ˆ
  - `verification.py` - ì–¼êµ´ ê²€ì¦ í‰ê°€
- **`eval_edgeface.py`** - EdgeFace ëª¨ë¸ í‰ê°€
- **`eval_ijbc.py`** - IJB-C ë²¤ì¹˜ë§ˆí¬ í‰ê°€
- **`onnx_ijbc.py`** - ONNX ëª¨ë¸ IJB-C í‰ê°€

#### ìœ í‹¸ë¦¬í‹°
- **`utils/`** - ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
  - `utils_config.py` - ì„¤ì • ê´€ë¦¬
  - `utils_logging.py` - ë¡œê¹…
  - `utils_callbacks.py` - í•™ìŠµ ì½œë°±
  - `utils_distributed_sampler.py` - ë¶„ì‚° í•™ìŠµ

#### ê¸°íƒ€
- **`configs/`** - í•™ìŠµ ì„¤ì • íŒŒì¼ë“¤
- **`inference.py`** - ëª¨ë¸ ì¶”ë¡  ì˜ˆì œ
- **`hubconf.py`** - PyTorch Hub ì„¤ì •
- **`torch2onnx.py`** - PyTorch â†’ ONNX ë³€í™˜
- **`onnx_helper.py`** - ONNX í—¬í¼ í•¨ìˆ˜
- **`flops.py`** - FLOPs ê³„ì‚°

### ğŸ“¦ ëª¨ë¸ ë° ë°ì´í„°

- **`face_alignment/models/`** - Face detection ëª¨ë¸ íŒŒì¼
  - `face_detection_yunet_2023mar.onnx` - YuNet ëª¨ë¸
  - `yolov8n.pt` - YOLOv8 nano ëª¨ë¸
  - `yolov5_face.onnx` - YOLOv5-Face ëª¨ë¸
  - `yolov8n-face*.onnx/pt` - YOLOv8 ì–¼êµ´ ëª¨ë¸ë“¤

- **`face_alignment/mtcnn_pytorch/data/`** - MTCNN ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜
  - `pnet.npy`, `rnet.npy`, `onet.npy`

- **`checkpoints/`** - EdgeFace ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸
  - `edgeface_xs_gamma_06.pt` - EdgeFace-XS(Î³=0.6) ëª¨ë¸

### ğŸ“Š ê²°ê³¼ ë° ì•„ì¹´ì´ë¸Œ

- **`benchmark_results/`** - ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ íŒŒì¼
  - CSV ë¦¬í¬íŠ¸
  - ì‹œê°í™” ì°¨íŠ¸ (PNG)

- **`alignment_results/`** - ì–¼êµ´ ì •ë ¬ ê²°ê³¼ ì´ë¯¸ì§€
  - ê° detectorë³„ ì •ë ¬ëœ ì–¼êµ´ ìƒ˜í”Œ

- **`archives/`** - ì•„ì¹´ì´ë¸Œ íŒŒì¼ë“¤
  - `notebooks/` - Jupyter ë…¸íŠ¸ë¶ ì‹¤í—˜ ì½”ë“œ
  - `analysis_scripts/` - ì¼íšŒì„± ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ (Quick Start)

### 1. ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”

Python 3.10 ê¶Œì¥ (3.8 ì´ìƒ ì§€ì›)

```bash
# Conda ì‚¬ìš© ì‹œ
conda create -n edgeface python=3.10
conda activate edgeface

# venv ì‚¬ìš© ì‹œ
python -m venv edgeface_env
source edgeface_env/bin/activate  # Linux/Mac
# edgeface_env\Scripts\activate  # Windows
```

### 2. PyTorch ì„¤ì¹˜ (GPU ë²„ì „ ê¶Œì¥)

**ë³¸ì¸ì˜ CUDA ë²„ì „ì— ë§ê²Œ ì„¤ì¹˜**í•˜ì„¸ìš”. GPU ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ì„ ìœ„í•´ì„œëŠ” CUDA ì§€ì› ë²„ì „ í•„ìˆ˜ì…ë‹ˆë‹¤.

```bash
# (https://pytorch.org/get-started/locally/ ì°¸ê³ )
# CUDA 12.8 ì˜ˆì‹œ
pip3 install torch torchvision

# CUDA 12.6 ì˜ˆì‹œ
pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu126

# CUDA 12.1 ì˜ˆì‹œ
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# CUDA 11.8 ì˜ˆì‹œ
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CPUë§Œ ì‚¬ìš©í•˜ëŠ” ê²½ìš° (ê¶Œì¥í•˜ì§€ ì•ŠìŒ)
pip install torch torchvision torchaudio
```

**ì„¤ì¹˜ í™•ì¸**:
```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA Available: {torch.cuda.is_available()}')"
```

### 3. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

**requirements.txtì— í¬í•¨ëœ ì£¼ìš” íŒ¨í‚¤ì§€**:
- `numpy`, `opencv-python`, `Pillow` - ì´ë¯¸ì§€ ì²˜ë¦¬
- `onnxruntime-gpu` - ONNX ëª¨ë¸ ì‹¤í–‰ (GPU ì§€ì›, YOLO detector í•„ìˆ˜)
- `ultralytics` - YOLOv8 detector (í•„ìˆ˜)
- `pandas`, `matplotlib`, `seaborn` - ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™”
- `scikit-learn` - í‰ê°€ ë©”íŠ¸ë¦­
- `tqdm`, `psutil` - ì§„í–‰ í‘œì‹œ ë° ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§

### 4. ì„ íƒì  íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
# MediaPipe detectorë¥¼ ì‚¬ìš©í•˜ë ¤ëŠ” ê²½ìš°
pip install mediapipe
```

### 5. LFW ë°ì´í„°ì…‹ ë° ëª¨ë¸ ì¤€ë¹„

ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì „ì— í•„ìš”í•œ íŒŒì¼ë“¤ì„ ì¤€ë¹„í•˜ì„¸ìš”:

1. **LFW ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ**: [LFW-deepfunneled](http://vis-www.cs.umass.edu/lfw/)
2. **EdgeFace ëª¨ë¸**: `checkpoints/edgeface_xs_gamma_06.pt`
3. **Face detection ëª¨ë¸ë“¤**: `face_alignment/models/` ë””ë ‰í† ë¦¬

### 6. LFW ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰

```bash
python face_alignment_benchmark_gpu.py
```

**ì„¤ì • ìˆ˜ì •**: `face_alignment_benchmark_gpu.py` íŒŒì¼ì—ì„œ
- `LFW_CONFIG['lfw_dir']` - LFW ë°ì´í„°ì…‹ ê²½ë¡œ
- `LFW_CONFIG['pairs_file']` - pairs.csv íŒŒì¼ ê²½ë¡œ
- `LFW_CONFIG['edgeface_model_path']` - EdgeFace ëª¨ë¸ ê²½ë¡œ
- `LFW_CONFIG['batch_size']` - GPU ë©”ëª¨ë¦¬ì— ë§ê²Œ ì¡°ì •
- `LFW_CONFIG['num_workers']` - CPU ì½”ì–´ ìˆ˜ì— ë§ê²Œ ì¡°ì •

### 6. ì‹¤ì‹œê°„ ì–¼êµ´ ì¸ì‹ ì‹œìŠ¤í…œ ì‹¤í–‰ (NEW!)

#### ğŸ¥ GUI ë²„ì „ (ê¶Œì¥)

EdgeFace ê¸°ë°˜ ì‹¤ì‹œê°„ ì–¼êµ´ ì¸ì‹ ì‹œìŠ¤í…œì„ GUIë¡œ í¸ë¦¬í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
# GUI ê¸°ë°˜ ì‹¤ì‹œê°„ ì–¼êµ´ ì¸ì‹ ì‹œìŠ¤í…œ ì‹¤í–‰
python face_recognition_gui.py
```

**ğŸ“– GUI ì‚¬ìš©ë²•**:

1. **ì‹œìŠ¤í…œ ì„¤ì •**
   - **Detector ì„ íƒ**: MTCNN, YuNet, **YuNet NPU**, YOLO ë“± ì„ íƒ
     - YOLOv8 ê¶Œì¥ (GPU)
     - YuNet NPU ê¶Œì¥ (ì„ë² ë””ë“œ ë³´ë“œ)
   - **Device ì„ íƒ**:
     - **CUDA (GPU)** - PC/ì›Œí¬ìŠ¤í…Œì´ì…˜
     - **CPU** - GPU ì—†ëŠ” í™˜ê²½
     - **NPU** - DeepX NPU íƒ‘ì¬ ì„ë² ë””ë“œ ë³´ë“œ (ğŸš€ ìµœì í™”)
   - **Similarity Threshold ì„¤ì •**: ì¸ì‹ ì„ê³„ê°’ ì¡°ì • (0.0~1.0, ê¸°ë³¸: 0.5)

   **ğŸ’¡ NPU ì‚¬ìš© ì‹œ**:
   - Deviceë¥¼ "NPU"ë¡œ ì„ íƒí•˜ë©´ ìë™ìœ¼ë¡œ YuNet NPUë¡œ ì „í™˜
   - EdgeFaceë„ ìë™ìœ¼ë¡œ NPU ëª¨ë¸ ì‚¬ìš© (.dxnn íŒŒì¼)
   - ğŸ“– [NPU ë¹ ë¥¸ ì‹œì‘](QUICKSTART_NPU.md) | [NPU í†µí•© ë¬¸ì„œ](NPU_INTEGRATION.md)

2. **ì¹´ë©”ë¼ ì‹œì‘**
   - "â–¶ Start Camera" ë²„íŠ¼ í´ë¦­
   - ì‹¤ì‹œê°„ìœ¼ë¡œ ì–¼êµ´ detection ë° recognition ì‹œì‘
   - FPS, ì¸ë¬¼ ID, ìœ ì‚¬ë„ê°€ í™”ë©´ì— í‘œì‹œë¨

3. **ì°¸ì¡° ì´ë¯¸ì§€ ë“±ë¡ (3ê°€ì§€ ë°©ë²•)**

   **ë°©ë²• 1: ğŸ“¸ ë‹¤ê°ë„ ìº¡ì²˜ (ê¶Œì¥ - ê°€ì¥ ì •í™•!)**
   - "ğŸ“¸ Capture Multi-Angle" ë²„íŠ¼ í´ë¦­
   - íŒì—… ì°½ì— ì´ë¦„ ì…ë ¥ í›„ í™•ì¸
   - í™”ë©´ ì§€ì‹œì— ë”°ë¼ ì–¼êµ´ì„ ì²œì²œíˆ ì›€ì§ì´ê¸°:
     - âœ… **ì •ë©´** (Front) - ì¹´ë©”ë¼ë¥¼ ë˜‘ë°”ë¡œ ë³´ê¸°
     - âœ… **ì¢Œ** (Left) - ì–¼êµ´ì„ ì™¼ìª½ìœ¼ë¡œ ì²œì²œíˆ ëŒë¦¬ê¸°
     - âœ… **ìš°** (Right) - ì–¼êµ´ì„ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì²œì²œíˆ ëŒë¦¬ê¸°
     - âœ… **ìœ„** (Up) - ì–¼êµ´ì„ ìœ„ë¡œ ì˜¬ë¦¬ê¸°
     - âœ… **í•˜** (Down) - ì–¼êµ´ì„ ì•„ë˜ë¡œ ë‚´ë¦¬ê¸°
   - ê° ê°ë„ê°€ ìë™ìœ¼ë¡œ ê°ì§€ë˜ë©´ ìë™ ìº¡ì²˜ë¨
   - ì§„í–‰ ìƒí™©ì´ í™”ë©´ì— ì‹¤ì‹œê°„ í‘œì‹œë¨ (ì˜ˆ: 3/5 ì™„ë£Œ)
   - 5ê°€ì§€ ê°ë„ ëª¨ë‘ ìº¡ì²˜ ì™„ë£Œ ì‹œ ìë™ìœ¼ë¡œ ë“±ë¡
   - ìº¡ì²˜ëœ ì´ë¯¸ì§€ëŠ” `captured_references/{ì´ë¦„}/` í´ë”ì— ê°ë„ë³„ë¡œ ì €ì¥

   **ë°©ë²• 2: ğŸ“ íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°**
   - "â• Add from File" ë²„íŠ¼ í´ë¦­
   - ì´ë¯¸ì§€ íŒŒì¼ ì„ íƒ (JPG, PNG ë“±)
   - íŒì—… ì°½ì— ì´ë¦„ ì…ë ¥ í›„ í™•ì¸
   - ìë™ìœ¼ë¡œ ì–¼êµ´ ê²€ì¶œ ë° ë“±ë¡ (ì •ë©´ ê°ë„ë¡œ ì €ì¥)

4. **ì°¸ì¡° ì´ë¯¸ì§€ ê´€ë¦¬**
   - ë“±ë¡ëœ ì¸ë¬¼ ëª©ë¡ì—ì„œ ì„ íƒ ì‹œ ìº¡ì²˜ëœ ê°ë„ ì •ë³´ í‘œì‹œ
   - "â– Remove Person" - ì„ íƒí•œ ì¸ë¬¼ ì „ì²´ ì‚­ì œ
   - "ğŸ—‘ï¸ Manage Angles" - íŠ¹ì • ê°ë„ë§Œ ì„ íƒ ì‚­ì œ ê°€ëŠ¥

5. **ì¹´ë©”ë¼ ì¢…ë£Œ**
   - "â¹ Stop Camera" ë²„íŠ¼ í´ë¦­

**ğŸ’¡ ì‚¬ìš© íŒ**:
- **GPU ì‚¬ìš© ê¶Œì¥**: ì²˜ë¦¬ ì†ë„ê°€ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤ (CUDA ì„ íƒ)
- **ë‹¤ê°ë„ ìº¡ì²˜ í™œìš©**: 5ê°€ì§€ ê°ë„ë¥¼ ëª¨ë‘ ìº¡ì²˜í•˜ë©´ ì¸ì‹ ì •í™•ë„ê°€ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤
- **Threshold ì¡°ì •**: ë†’ì„ìˆ˜ë¡ ì—„ê²©í•˜ê²Œ ì¸ì‹ (0.5~0.7 ê¶Œì¥)
- **ì¡°ëª… ì£¼ì˜**: ë°ê³  ê· ì¼í•œ ì¡°ëª…ì—ì„œ ìº¡ì²˜í•˜ë©´ ì¸ì‹ë¥  í–¥ìƒ
- **ë‹¤ì¤‘ ì¸ë¬¼ ì¸ì‹**: 2ëª… ì´ìƒì´ ë™ì‹œì— í™”ë©´ì— ìˆì–´ë„ ì•ˆì •ì ìœ¼ë¡œ ì¸ì‹ë©ë‹ˆë‹¤
- **ì•ˆì •ì ì¸ ì¶”ì **: IoU ê¸°ë°˜ ì¶”ì ìœ¼ë¡œ í”„ë ˆì„ ê°„ identity ê¹œë¹¡ì„ ë°©ì§€

#### âŒ¨ï¸ ì»¤ë§¨ë“œë¼ì¸ ë²„ì „

```bash
# 1. íŒŒì¼ì—ì„œ ì°¸ì¡° ì´ë¯¸ì§€ ì¶”ê°€
python face_recognition_system.py --add-ref path/to/person.jpg "Person Name"

# 2. ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ì¸ì‹ ì‹¤í–‰
python face_recognition_system.py --detector mtcnn --device cuda

# 3. ì‹¤í–‰ ì¤‘ í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤ ì‚¬ìš©
#    - 'c' í‚¤: ì¹´ë©”ë¼ì—ì„œ ì§ì ‘ ìº¡ì²˜í•˜ì—¬ ì°¸ì¡° ì´ë¯¸ì§€ ë“±ë¡
#    - 'q' í‚¤: í”„ë¡œê·¸ë¨ ì¢…ë£Œ

# 4. ì˜µì…˜ ì»¤ìŠ¤í„°ë§ˆì´ì§•
python face_recognition_system.py \
  --detector yolov8 \
  --device cuda \
  --threshold 0.6 \
  --camera 0
```

**ì£¼ìš” ì˜µì…˜**:
- `--detector`: ì–¼êµ´ detection ë°©ë²• (mtcnn, yunet, yolov5_face, yolov8)
- `--device`: ì‹¤í–‰ ë””ë°”ì´ìŠ¤ (cuda, cpu)
- `--threshold`: ìœ ì‚¬ë„ ì„ê³„ê°’ (ê¸°ë³¸: 0.5)
- `--camera`: ì¹´ë©”ë¼ ID (ê¸°ë³¸: 0, ì›¹ìº )
- `--add-ref IMAGE ID`: íŒŒì¼ì—ì„œ ì°¸ì¡° ì´ë¯¸ì§€ ì¶”ê°€

**ì‹¤í–‰ ì¤‘ í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤**:
- `q`: í”„ë¡œê·¸ë¨ ì¢…ë£Œ
- `c`: í˜„ì¬ í”„ë ˆì„ì„ ìº¡ì²˜í•˜ì—¬ ì°¸ì¡° ì´ë¯¸ì§€ë¡œ ë“±ë¡

**ğŸ“¦ ì°¸ì¡° ë°ì´í„°ë² ì´ìŠ¤**:
- ì°¸ì¡° ì´ë¯¸ì§€ëŠ” `reference_db.pkl` íŒŒì¼ì— ì €ì¥ë¨
- GUI ë˜ëŠ” ì»¤ë§¨ë“œë¼ì¸ì—ì„œ ì¶”ê°€/ì‚­ì œ ê°€ëŠ¥
- ì–¼êµ´ ì„ë² ë”©ì€ EdgeFace ëª¨ë¸ë¡œ ì¶”ì¶œí•˜ì—¬ ì €ì¥
- ìº¡ì²˜ëœ ì´ë¯¸ì§€ëŠ” `captured_references/` í´ë”ì— ìë™ ì €ì¥

**ğŸ¯ ì¸ì‹ í”„ë¡œì„¸ìŠ¤**:
1. ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ ì½ê¸°
2. Face detectorë¡œ ì–¼êµ´ ê²€ì¶œ ë° ëœë“œë§ˆí¬ ì¶”ì¶œ (ë™ì‹œì— ì—¬ëŸ¬ ì–¼êµ´)
3. ì–¼êµ´ ì •ë ¬ (Face alignment) - ëª¨ë“  ê²€ì¶œëœ ì–¼êµ´
4. **ë°°ì¹˜ ì²˜ë¦¬**: EdgeFace ëª¨ë¸ë¡œ 512ì°¨ì› ì„ë² ë”© ë™ì‹œ ì¶”ì¶œ (GPU ìµœì í™”)
5. ì°¸ì¡° DBì™€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ëª¨ë“  ê°ë„ ë¹„êµ)
6. **Greedy Assignment**: ê° ì–¼êµ´ì— ìµœì ì˜ ì¸ë¬¼ ë§¤ì¹­
7. **Face Tracking**: IoU ê¸°ë°˜ìœ¼ë¡œ ì´ì „ í”„ë ˆì„ê³¼ ì—°ê²°í•˜ì—¬ ì¼ê´€ì„± ìœ ì§€
8. Threshold ì´ìƒì´ë©´ ì¸ë¬¼ ID í‘œì‹œ

**âš¡ ì„±ëŠ¥ ìµœì í™”**:
- **ë°°ì¹˜ ì„ë² ë”© ì¶”ì¶œ**: ì—¬ëŸ¬ ì–¼êµ´ì„ í•œ ë²ˆì— ì²˜ë¦¬í•˜ì—¬ ~2ë°° ë¹ ë¦„
- **Face Tracking**: 10í”„ë ˆì„ê¹Œì§€ ì¶”ì í•˜ì—¬ ê¹œë¹¡ì„ ì œê±°
- **ìš°ì„ ìˆœìœ„ ë§¤ì¹­**: ì¶”ì ëœ ì–¼êµ´ì€ threshold 0.8ë°°ë¡œ ë‚®ì¶° ì•ˆì •ì„± í–¥ìƒ
- **ë‹¤ê°ë„ DB**: 5ê°€ì§€ ê°ë„ ì €ì¥ìœ¼ë¡œ ë‹¤ì–‘í•œ í¬ì¦ˆì—ì„œ ë†’ì€ ì¸ì‹ë¥ 

### 7. NPU ëª¨ë¸ í…ŒìŠ¤íŠ¸ (ì„ë² ë””ë“œ ë³´ë“œ)

DeepX NPU íƒ‘ì¬ ì„ë² ë””ë“œ ë³´ë“œì—ì„œ NPU ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
# NPU í†µí•© í…ŒìŠ¤íŠ¸ (EdgeFace + YuNet)
python test_npu_inference.py
```

**í…ŒìŠ¤íŠ¸ ë‚´ìš©**:
- EdgeFace NPU: 512ì°¨ì› ì„ë² ë”© ì¶œë ¥ ê²€ì¦
- YuNet NPU: ì–¼êµ´ ê²€ì¶œ ì¶œë ¥ í˜•ì‹ ë¶„ì„
- ê° ëª¨ë¸ì˜ ì¶œë ¥ shape, í†µê³„, L2 norm í™•ì¸

**í˜„ì¬ ìƒíƒœ**:
- âœ… EdgeFace NPU: ì •ìƒ ë™ì‘ í™•ì¸ (L2 norm = 1.0)
- âœ… YuNet NPU: ì¶œë ¥ ë””ì½”ë”© ì™„ë£Œ, ì •ìƒ ë™ì‘ í™•ì¸

### 8. LFW ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰

```bash
python face_alignment_benchmark_gpu.py
```

**ì„¤ì • ìˆ˜ì •**: `face_alignment_benchmark_gpu.py` íŒŒì¼ì—ì„œ
- `LFW_CONFIG['lfw_dir']` - LFW ë°ì´í„°ì…‹ ê²½ë¡œ
- `LFW_CONFIG['pairs_file']` - pairs.csv íŒŒì¼ ê²½ë¡œ
- `LFW_CONFIG['edgeface_model_path']` - EdgeFace ëª¨ë¸ ê²½ë¡œ
- `LFW_CONFIG['batch_size']` - GPU ë©”ëª¨ë¦¬ì— ë§ê²Œ ì¡°ì •
- `LFW_CONFIG['num_workers']` - CPU ì½”ì–´ ìˆ˜ì— ë§ê²Œ ì¡°ì •

### 9. íŠ¹ì • Detector ì‚¬ìš©í•˜ê¸° (Python API)

```python
from face_alignment.unified_detector import UnifiedFaceDetector

# Detector ì´ˆê¸°í™”
detector = UnifiedFaceDetector('mtcnn', device='cuda')

# ì–¼êµ´ ê²€ì¶œ
from PIL import Image
image = Image.open('face.jpg')
bboxes, landmarks = detector.detect_faces(image)

# ì–¼êµ´ ì •ë ¬
aligned_face = detector.align(image)
```

**ì‚¬ìš© ê°€ëŠ¥í•œ methods**:
- `mtcnn` - MTCNN
- `yunet` - YuNet (OpenCV DNN)
- `yunet_npu` - YuNet NPU (DeepX NPU) âœ… ì‚¬ìš© ê°€ëŠ¥
- `yolov5_face` - YOLOv5-Face
- `yolov8` - YOLOv8
- `retinaface` - RetinaFace (ONNX)
- `rtmpose` - RTMPose (ONNX)
- `mediapipe` - MediaPipe Face Mesh
- `mediapipe_simple` - MediaPipe Face Detection

## ğŸ“ˆ ë²¤ì¹˜ë§ˆí¬ ë©”íŠ¸ë¦­

1. **Accuracy** - ì–¼êµ´ ê²€ì¦ ì •í™•ë„
2. **ROC AUC** - ROC ê³¡ì„  ì•„ë˜ ë©´ì 
3. **EER** - Equal Error Rate (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
4. **Success Rate** - ì–¼êµ´ ê²€ì¶œ ì„±ê³µë¥ 
5. **Processing Time** - ì´ë¯¸ì§€ë‹¹ ì²˜ë¦¬ ì‹œê°„
6. **Memory Usage** - CPU/GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

## ğŸ“ ì£¼ìš” íŠ¹ì§•

### NPU Calibration ì‹œìŠ¤í…œ (NEW! ğŸ”¥)
- âœ… **ONNX â†’ NPU ì»´íŒŒì¼ì„ ìœ„í•œ ì™„ì „ ìë™í™”ëœ calibration ì‹œìŠ¤í…œ**
- âœ… **YuNet (Detection)**: ì¼ë°˜ ì´ë¯¸ì§€ë¡œ calibration
  - 5ê°€ì§€ í’ˆì§ˆ ì§€í‘œë¡œ ìë™ ì´ë¯¸ì§€ ì„ íƒ (ì„ ëª…ë„, ë°ê¸°, ëŒ€ë¹„, í•´ìƒë„, ìƒ‰ìƒ)
  - ë‹¤ì–‘ì„± ë³´ì¥ ìƒ˜í”Œë§ ì „ëµ
- âœ… **EdgeFace (Recognition)**: ì •ë ¬ëœ ì–¼êµ´ë¡œ calibration
  - YuNetìœ¼ë¡œ ìë™ ì–¼êµ´ detection + alignment
  - 112x112 ì •ë ¬ëœ ì–¼êµ´ ì´ë¯¸ì§€ ìƒì„±
  - ArcFace ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì ìš©
- âœ… **NPU calibration config JSON ìë™ ìƒì„±**
  - ëª¨ë¸ë³„ ìµœì í™”ëœ ì „ì²˜ë¦¬ ì„¤ì •
  - BGR/RGB ë³€í™˜, ì •ê·œí™” ìë™ ì²˜ë¦¬
- âœ… **4ê°€ì§€ calibration ë°©ë²•**: EMA (ê¶Œì¥), MinMax, KL, Percentile
- âœ… **ê²€ì¦ ë„êµ¬**: ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ë° ì‹œê°í™”
- âœ… **ì™„ì „ ìë™í™” ìŠ¤í¬ë¦½íŠ¸**: í•œ ì¤„ ëª…ë ¹ì–´ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
- ğŸ“– [NPU Calibration ê°€ì´ë“œ](npu_calibration/README.md)

### ONNX ë³€í™˜ ë° í‰ê°€ (NEW! ğŸ”¥)
- âœ… **EdgeFace PyTorch â†’ ONNX ë³€í™˜**
  - ONNX opset 11 ì‚¬ìš©
  - NPU calibration configì™€ ì¼ì¹˜í•˜ëŠ” ì…ë ¥ ì´ë¦„ (input.1)
  - ë™ì  ë°°ì¹˜ í¬ê¸° ì§€ì›
  - ëª¨ë¸ ê²€ì¦ ë° ì¶œë ¥ ë¹„êµ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„, ì°¨ì´ ê³„ì‚°)
- âœ… **LFW ë°ì´í„°ì…‹ ì„±ëŠ¥ í‰ê°€**
  - PyTorch ëª¨ë¸ vs ONNX ëª¨ë¸ ë¹„êµ
  - ROC AUC, ì •í™•ë„, EER, ì²˜ë¦¬ ì†ë„ ì¸¡ì •
  - ìœ ì‚¬ë„ ë¶„í¬ ë¹„êµ ì‹œê°í™”
- âœ… **Jupyter Notebook í˜•ì‹**
  - ë‹¨ê³„ë³„ ìƒì„¸í•œ í•œêµ­ì–´ ì„¤ëª…
  - ì¸í„°ë™í‹°ë¸Œ ì‹¤í–‰ ë° ì‹œê°í™”
  - ì„±ëŠ¥ ë¹„êµ ë¦¬í¬íŠ¸ ìë™ ìƒì„±

### ì‹¤ì‹œê°„ ì–¼êµ´ ì¸ì‹ ì‹œìŠ¤í…œ
- âœ… **GUI ê¸°ë°˜ ì‚¬ìš©ì ì¹œí™”ì  ì¸í„°í˜ì´ìŠ¤** (Tkinter)
- âœ… **ì‹¤ì‹œê°„ ì–¼êµ´ detection ë° recognition**
- âœ… **ì°¸ì¡° ì´ë¯¸ì§€ ê´€ë¦¬** (ì¶”ê°€/ì‚­ì œ)
  - ğŸ“¸ **ì¹´ë©”ë¼ ì§ì ‘ ìº¡ì²˜**: ì‹¤ì‹œê°„ìœ¼ë¡œ ì–¼êµ´ ì´¬ì˜í•˜ì—¬ ë“±ë¡
  - ğŸ”„ **ë‹¤ê°ë„ ì–¼êµ´ ìº¡ì²˜**: ì •ë©´/ì¢Œ/ìš°/ìœ„/ì•„ë˜ 5ê°€ì§€ ê°ë„ ìë™ ìº¡ì²˜ (NEW!)
  - ğŸ“ **íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°**: ê¸°ì¡´ ì´ë¯¸ì§€ íŒŒì¼ ì„ íƒ
- âœ… **ë‹¤ì¤‘ detector ì„ íƒ** (MTCNN, YuNet, YOLO ë“±)
- âœ… **EdgeFace ê¸°ë°˜ ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ**
- âœ… **ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ì¦**
- âœ… **ë°°ì¹˜ ì„ë² ë”© ì¶”ì¶œ**: ì—¬ëŸ¬ ì–¼êµ´ì„ ë™ì‹œì— ì²˜ë¦¬í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ (NEW!)
- âœ… **ì–¼êµ´ ì¶”ì  (Face Tracking)**: IoU ê¸°ë°˜ í”„ë ˆì„ ê°„ ì¼ê´€ì„± ìœ ì§€ (NEW!)
- âœ… **ì•ˆì •ì ì¸ ë‹¤ì¤‘ ì¸ë¬¼ ì¸ì‹**: 2ëª… ì´ìƒë„ ê¹œë¹¡ì„ ì—†ì´ ì•ˆì •ì  ì¸ì‹ (NEW!)
- âœ… **FPS, ì¸ë¬¼ ID, ìœ ì‚¬ë„ ì‹¤ì‹œê°„ í‘œì‹œ**
- âœ… **GPU ê°€ì† ì§€ì›**
- âœ… **ìº¡ì²˜ëœ ì´ë¯¸ì§€ ìë™ ì €ì¥** (captured_references/)

### LFW ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œ
- âœ… **7ê°€ì§€ face detection ë°©ë²•** í†µí•© ì§€ì›
- âœ… **GPU ìµœì í™”** ë°°ì¹˜ ì²˜ë¦¬
- âœ… **ìë™ ë©”ëª¨ë¦¬ ì¶”ì ** (CPU/GPU)
- âœ… **ë³‘ë ¬ ì´ë¯¸ì§€ ë¡œë”©** (ThreadPoolExecutor)
- âœ… **ìë™ CUDA fallback** (YuNet, ONNX Runtime)
- âœ… **í†µí•© ì¸í„°í˜ì´ìŠ¤** (ë‹¨ì¼ API)
- âœ… **ì¢…í•© ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŠ¸** (CSV + ì‹œê°í™”)

## ğŸ”§ YuNet NPU ìƒì„¸ ê°€ì´ë“œ

### YuNet NPU ì¶œë ¥ êµ¬ì¡°

YuNet ONNX ëª¨ë¸ì„ DeepX NPUë¡œ ì»´íŒŒì¼í•˜ë©´ **ì¶œë ¥ êµ¬ì¡°ê°€ ë³€ê²½**ë©ë‹ˆë‹¤:

#### ì›ë³¸ ONNX ëª¨ë¸ ì¶œë ¥ (12ê°œ)
- Feature Pyramid Network (FPN) ê¸°ë°˜ 3-scale detection
- ê° scaleë‹¹ 4ê°€ì§€ ì¶œë ¥: cls, obj, bbox, kps
- ì¶œë ¥ ì´ë¦„: `cls_8`, `cls_16`, `cls_32`, `obj_8`, `obj_16`, `obj_32`, `bbox_8`, `bbox_16`, `bbox_32`, `kps_8`, `kps_16`, `kps_32`
- **Post-processing í¬í•¨**: NMS, bbox decoding ë“±ì´ ONNX ëª¨ë¸ ë‚´ë¶€ì— êµ¬í˜„ë¨

#### NPU ì»´íŒŒì¼ëœ ëª¨ë¸ ì¶œë ¥ (13ê°œ)
- DeepX NPU ì»´íŒŒì¼ëŸ¬ê°€ **ì¶œë ¥ ìˆœì„œë¥¼ ì¬ë°°ì—´**
- **Post-processing ì œê±°**: NMS, bbox decodingì´ ì œê±°ë˜ì–´ raw feature map ì¶œë ¥
- 13ê°œ í…ì„œ ì¶œë ¥ (spatial feature map 1ê°œ + FPN outputs 12ê°œ)

```python
# NPU ì¶œë ¥ ë§¤í•‘ ì˜ˆì‹œ (user's compiled version)
Output 0:  (1, 1, 80, 80)    # Spatial feature map (unused)
Output 1:  (1, 6400, 1)      # cls_8 (stride 8, 80x80 = 6400 anchors)
Output 2:  (1, 1600, 1)      # cls_16 (stride 16, 40x40 = 1600 anchors)
Output 3:  (1, 6400, 4)      # bbox_8
Output 4:  (1, 1600, 4)      # bbox_16
Output 5:  (1, 1600, 1)      # obj_16
Output 6:  (1, 400, 10)      # kps_32 (stride 32, 20x20 = 400 anchors)
Output 7:  (1, 6400, 10)     # kps_8
Output 8:  (1, 1600, 10)     # kps_16
Output 9:  (1, 400, 1)       # obj_32
Output 10: (1, 400, 4)       # bbox_32
Output 11: (1, 6400, 1)      # obj_8
Output 12: (1, 400, 1)       # cls_32
```

**âš ï¸ ì¤‘ìš”**: NPU ì»´íŒŒì¼ëŸ¬ ë²„ì „ì´ë‚˜ ì„¤ì •ì— ë”°ë¼ ì¶œë ¥ ìˆœì„œê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤!

### YuNet NPU ë””ì½”ë”© êµ¬í˜„

NPU ëª¨ë¸ì˜ raw ì¶œë ¥ì„ bbox/landmarkë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •:

#### 1. Score ê³„ì‚°
```python
# YuNetì€ cls Ã— objë¥¼ final confidenceë¡œ ì‚¬ìš©
score = cls_score * obj_score
```

#### 2. Anchor ê¸°ë°˜ Bbox ë””ì½”ë”©
```python
# Anchor ìœ„ì¹˜ ê³„ì‚° (grid ì¢Œìƒë‹¨ ê¸°ì¤€, 0.5 offset ì—†ìŒ)
feat_size = input_size // stride  # 640/32 = 20 for stride 32
anchor_y = idx // feat_size
anchor_x = idx % feat_size

# Center ë””ì½”ë”© (offset scaling)
cx = (anchor_x + bbox[0] * 0.5) * stride
cy = (anchor_y + bbox[1] * 0.5) * stride

# Size ë””ì½”ë”© (linear scaling with prior)
prior_size = stride * 3  # ë˜ëŠ” stride * 4
w = bbox[2] * prior_size
h = bbox[3] * prior_size

# Top-left corner í˜•ì‹ìœ¼ë¡œ ë³€í™˜
x = cx - w / 2
y = cy - h / 2
```

#### 3. Landmark ë””ì½”ë”©
```python
# Landmarksë„ anchor ê¸°ì¤€ offset
for i in range(5):  # 5 keypoints
    lm_x = (anchor_x + lms[i*2] * 1.0) * stride
    lm_y = (anchor_y + lms[i*2 + 1] * 1.0) * stride
```

#### 4. Multi-scale Detection
```python
# 3ê°œ scaleì˜ detectionì„ ëª¨ë‘ ìˆ˜ì§‘
detections_stride8 = process_scale(..., stride=8)   # 80x80 feature map
detections_stride16 = process_scale(..., stride=16) # 40x40 feature map
detections_stride32 = process_scale(..., stride=32) # 20x20 feature map

# ëª¨ë“  detection í•©ì¹˜ê¸°
all_detections = detections_stride8 + detections_stride16 + detections_stride32
```

#### 5. NMS (Non-Maximum Suppression)
```python
# ì¤‘ë³µ detection ì œê±°
final_detections = apply_nms(all_detections, iou_threshold=0.3)
```

### Bbox/Landmark ì¡°ì • ë°©ë²•

Detection ê²°ê³¼ê°€ ì •í™•í•˜ì§€ ì•Šì„ ë•Œ ì¡°ì •í•˜ëŠ” ë°©ë²•:

#### íŒŒì¼ ìœ„ì¹˜
`face_alignment/yunet_npu.py`ì˜ `_process_scale()` ë©”ì„œë“œ (ë¼ì¸ ~295-325)

#### ì¡°ì • íŒŒë¼ë¯¸í„°

1. **Bbox í¬ê¸° ì¡°ì •** (`prior_size`)
   ```python
   prior_size = stride * 3  # ì´ ê°’ì„ ì¡°ì •
   # í¬ê²Œ: stride * 4, stride * 5
   # ì‘ê²Œ: stride * 2, stride * 1.5
   ```

2. **Bbox width/height ë¹„ìœ¨ ì¡°ì •**
   ```python
   # ì •ì‚¬ê°í˜•ì´ ì•„ë‹Œ ì–¼êµ´ ë¹„ìœ¨ ì ìš©
   prior_w = stride * 3    # width
   prior_h = stride * 4    # height (ë” ê¸¸ê²Œ)
   w = bbox[2] * prior_w
   h = bbox[3] * prior_h
   ```

3. **Bbox center offset ì¡°ì •**
   ```python
   # ìœ„ì¹˜ shift ì¡°ì • (í˜„ì¬ 0.5)
   cx = (anchor_x + bbox[0] * 0.5) * stride  # 0.5ë¥¼ 0.3~1.0 ì‚¬ì´ë¡œ ì¡°ì •
   cy = (anchor_y + bbox[1] * 0.5) * stride

   # ìš°í•˜ë‹¨ìœ¼ë¡œ ì¹˜ìš°ì¹˜ë©´: ê³„ìˆ˜ë¥¼ ì¤„ì„ (0.3, 0.4)
   # ì¢Œìƒë‹¨ìœ¼ë¡œ ì¹˜ìš°ì¹˜ë©´: ê³„ìˆ˜ë¥¼ ëŠ˜ë¦¼ (0.7, 0.8)
   ```

4. **Landmark offset ì¡°ì •**
   ```python
   # í˜„ì¬ 1.0 ê³„ìˆ˜ ì‚¬ìš©
   lm_x = (anchor_x + lms[i*2] * 1.0) * stride  # 1.0ì„ ì¡°ì •
   lm_y = (anchor_y + lms[i*2 + 1] * 1.0) * stride

   # Landmarkê°€ bbox centerì™€ í•¨ê»˜ ì›€ì§ì´ì§€ ì•Šìœ¼ë©´ bbox center ê¸°ì¤€ìœ¼ë¡œ:
   lm_x = cx + lms[i*2] * w  # bbox í¬ê¸° ê¸°ì¤€
   lm_y = cy + lms[i*2 + 1] * h
   ```

5. **Anchor 0.5 offset**
   ```python
   # í˜„ì¬: anchorëŠ” grid ì¢Œìƒë‹¨ (0.5 offset ì—†ìŒ)
   anchor_y = (idx // feat_size)
   anchor_x = (idx % feat_size)

   # Grid centerë¥¼ ì‚¬ìš©í•˜ë ¤ë©´:
   anchor_y = (idx // feat_size) + 0.5
   anchor_x = (idx % feat_size) + 0.5
   ```

#### Debug ì¶œë ¥ í™œìš©

ì½”ë“œ ì‹¤í–‰ ì‹œ ë‹¤ìŒê³¼ ê°™ì€ debug ì •ë³´ê°€ ì¶œë ¥ë©ë‹ˆë‹¤:

```
[DEBUG] Scale 3 (stride 32): score range [0.000000, 0.810580], mean=0.015924
[DEBUG]   Stride 32: 7/400 above threshold 0.6
[DEBUG]     First valid score: 0.7965272068977356
[DEBUG]     First valid bbox raw: [0.9806061 1.3796387 1.3396912 1.7766724]
[DEBUG]     First valid landmark raw: [-0.03892517  0.46404266  1.4368286 ...]
```

ì´ ê°’ë“¤ì„ ë³´ë©´ì„œ:
- `bbox raw` ê°’ì´ í¬ë©´ (>2.0) â†’ offset scaling ì¤„ì´ê¸°
- `bbox[2]`, `bbox[3]` (width/height scale) â†’ 1.0~2.0 ì‚¬ì´ë©´ linear, >3.0ì´ë©´ exponential ê³ ë ¤
- Landmark ê°’ì˜ ë²”ìœ„ â†’ bboxì™€ ë¹„ìŠ·í•œ ìŠ¤ì¼€ì¼ì´ë©´ ê°™ì€ ë°©ì‹ ì ìš©

### NPU ì»´íŒŒì¼ ì‹œ ì£¼ì˜ì‚¬í•­

1. **ì¶œë ¥ ìˆœì„œ í™•ì¸ í•„ìˆ˜**
   - ë‹¤ë¥¸ ë²„ì „ìœ¼ë¡œ ì»´íŒŒì¼í•˜ë©´ ì¶œë ¥ ìˆœì„œê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
   - `test_npu_inference.py` ì‹¤í–‰í•´ì„œ shape í™•ì¸
   - `_decode_outputs()` ë©”ì„œë“œì—ì„œ output ë§¤í•‘ ìˆ˜ì •

2. **Post-processing ì œê±°ë¨**
   - ONNX ëª¨ë¸ì˜ NMS, bbox decodingì´ ì œê±°ë¨
   - Pythonì—ì„œ ì§ì ‘ êµ¬í˜„ í•„ìš”

3. **Calibration ë°ì´í„° ì¤‘ìš”**
   - YuNetì€ ë‹¤ì–‘í•œ ì–¼êµ´ í¬ê¸°/ê°ë„ ì´ë¯¸ì§€ë¡œ calibration
   - `npu_calibration/` ì‹œìŠ¤í…œ í™œìš© ê¶Œì¥

4. **ì…ë ¥ ì „ì²˜ë¦¬**
   - YuNet: RGB, HWC format, uint8
   - 640x640 ì…ë ¥ í¬ê¸°

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### WSL ì¹´ë©”ë¼ ì—°ê²° ì„¤ì •

WSL2ì—ì„œ USB ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ Windowsì˜ PowerShellì—ì„œ USB ì¥ì¹˜ë¥¼ WSLë¡œ ì—°ê²°í•´ì•¼ í•©ë‹ˆë‹¤.

**1. PowerShellì—ì„œ USB ì¥ì¹˜ í™•ì¸** (ê´€ë¦¬ì ê¶Œí•œ í•„ìš”)
```powershell
usbipd list
```

**2. ì¹´ë©”ë¼ ì—°ê²°**
```powershell
# busidëŠ” ìœ„ì—ì„œ í™•ì¸í•œ ì¹´ë©”ë¼ì˜ BUSIDë¡œ ëŒ€ì²´
usbipd attach --wsl --busid <busid>
```

**3. ì—°ê²° í™•ì¸**
```powershell
usbipd list
# "Attached" ìƒíƒœì¸ì§€ í™•ì¸
```

**4. WSLì—ì„œ ì¹´ë©”ë¼ ì¸ì‹ í™•ì¸**
```bash
# USB ì¥ì¹˜ ëª©ë¡ í™•ì¸
lsusb

# ë¹„ë””ì˜¤ ì¥ì¹˜ í™•ì¸
ll /dev/video*
```

ì¹´ë©”ë¼ê°€ ì •ìƒì ìœ¼ë¡œ ì—°ê²°ë˜ë©´ `/dev/video0` ë“±ì˜ ì¥ì¹˜ê°€ í‘œì‹œë©ë‹ˆë‹¤.

### CUDA ê´€ë ¨
- **TensorFlow CUDA ê²½ê³ **: RTX 5090 ë“± ìµœì‹  GPUëŠ” JIT ì»´íŒŒì¼ ì‚¬ìš© (ì •ìƒ ë™ì‘)
- **OpenCV CUDA ì—†ìŒ**: YuNetì´ ìë™ìœ¼ë¡œ CPUë¡œ fallback
- **ONNX Runtime CUDA ì—†ìŒ**: CPU ë²„ì „ ì‚¬ìš© ì¤‘ (onnxruntime-gpu ì„¤ì¹˜ í•„ìš”)

### ë©”ëª¨ë¦¬ ê´€ë ¨
- `batch_size` ì¤„ì´ê¸° (ê¸°ë³¸: 64)
- `num_workers` ì¡°ì • (ê¸°ë³¸: 8)
- GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ì¼ë¶€ detector ì œì™¸

### Detector ì˜¤ë¥˜
- **MTCNN**: PyTorch GPU ì„¤ì¹˜ í•„ìš”
- **YuNet**: OpenCV ì„¤ì¹˜ í•„ìš”
- **YOLO**: Ultralytics ë° ONNX Runtime GPU í•„ìˆ˜ (`pip install ultralytics onnxruntime-gpu`)
- **MediaPipe**: mediapipe íŒ¨í‚¤ì§€ ì„¤ì¹˜ í•„ìš”

### íŒ¨í‚¤ì§€ ì„¤ì¹˜ ìˆœì„œ ìš”ì•½

ì™„ì „íˆ ìƒˆë¡œìš´ í™˜ê²½ì—ì„œ ì‹œì‘í•˜ëŠ” ê²½ìš°:

```bash
# 1. ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
conda create -n edgeface python=3.10
conda activate edgeface

# 2. PyTorch ì„¤ì¹˜ (CUDA ë²„ì „ì— ë§ê²Œ)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# 3. requirements.txt ì„¤ì¹˜
pip install -r requirements.txt

# 4. (ì„ íƒ) MediaPipe
pip install mediapipe

# 5. ì„¤ì¹˜ í™•ì¸
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
python -c "from ultralytics import YOLO; print('Ultralytics OK')"
```

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì›ë³¸ EdgeFace í”„ë¡œì íŠ¸ì˜ ë¼ì´ì„ ìŠ¤ë¥¼ ë”°ë¦…ë‹ˆë‹¤.

## ğŸ™ ê°ì‚¬

- EdgeFace ì›ë³¸ í”„ë¡œì íŠ¸ (https://github.com/otroshi/edgeface)
- OpenCV YuNet
- Ultralytics YOLOv8
- MediaPipe
